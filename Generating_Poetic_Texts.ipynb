{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQXb728MwVRH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "id": "4-3m3bUHw1ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "UNLPNiEjw1gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "metadata": {
        "id": "Ski876njw1bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])\n",
        "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=np.bool_)\n",
        "y = np.zeros((len(sentences), len(characters)), dtype=np.bool_)\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "metadata": {
        "id": "xB6B9eUVw1Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate =0.01))\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imW_YqLMw1O6",
        "outputId": "2415e084-7466-4794-d97f-214367ace5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1953/1953\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 165ms/step - loss: 2.1163\n",
            "Epoch 2/4\n",
            "\u001b[1m1953/1953\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 163ms/step - loss: 1.4982\n",
            "Epoch 3/4\n",
            "\u001b[1m1953/1953\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 163ms/step - loss: 1.3919\n",
            "Epoch 4/4\n",
            "\u001b[1m1953/1953\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 163ms/step - loss: 1.3400\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b18e8bf6950>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "Bi9y1junw1Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "royYUcgIw07b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))\n",
        "print(generate_text(300, 0.4))\n",
        "print(generate_text(300, 0.5))\n",
        "print(generate_text(300, 0.6))\n",
        "print(generate_text(300, 0.7))\n",
        "print(generate_text(300, 0.8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0f3ne9Yw0uo",
        "outputId": "3e7f189b-0e60-4688-ad83-6247fb799342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in their purses, and whoso empties them\n",
            "shall hear the father's son is despain to stay.\n",
            "\n",
            "king richard ii:\n",
            "the lady brother to the best with the sead.\n",
            "\n",
            "king richard ii:\n",
            "i will speak the counter to the seen, and\n",
            "thou wilt to the winds not the streeper for the countrymen\n",
            "and thou wert thou deserve the father's lady.\n",
            "\n",
            "king henry vi:\n",
            "why, he i\n",
            "d hearts of maids: it was\n",
            "thought she was to the such a king's paris.\n",
            "\n",
            "duke of york:\n",
            "what said, that thou wert i will thou care\n",
            "that i will thou day not for my chard.\n",
            "\n",
            "clown:\n",
            "what sit a most reason, the boy:\n",
            "for the cause of your both drows of the chance.\n",
            "\n",
            "clarence:\n",
            "i see the more than to the world out the earth\n",
            "from my cousin of the seas\n",
            "omas of norfolk, what say'st thou to thine.\n",
            "\n",
            "warwick:\n",
            "i shall diding, and to see thee fearth and\n",
            "that sould sould shall not so firsa; lies\n",
            "and thou wilt thou wert mer sting.\n",
            "\n",
            "leontes:\n",
            "thou wert made the seeming and his son sour,\n",
            "i will thou with me into the diegrate the clarence\n",
            "and speak to us to live so most again;\n",
            "and all the earth, th\n",
            " way, like a mighty sea\n",
            "forced by the times are to go, we prince,\n",
            "i have dood with must are to the world prossed her;\n",
            "for with when their so, then he will feel thee,\n",
            "and with my sup but she contires profess.\n",
            "\n",
            "king henry:ivi:\n",
            "\n",
            "clown:\n",
            "i must not for the grief:\n",
            "and what for long and here is the world:\n",
            "then will have seen to the more for a ki\n",
            "e with any thing\n",
            "that you behold the while are i have not\n",
            "the cellors:\n",
            "what save in day disposine warwick, blaze\n",
            "i will it were of lotter, the world, did.\n",
            "\n",
            "king henry vi:\n",
            "what sorrow charged the boy, for avisely.\n",
            "\n",
            "king edward ivi:\n",
            "\n",
            "bries hence:\n",
            "here in the seepecties wexch shall be them?\n",
            "\n",
            "romeo:\n",
            "not in the first what is not my lord; and a\n",
            " her immortal part with angels lives.\n",
            "i conceing to a sorrow in with your are:\n",
            "but well i never did you are me!\n",
            "\n",
            "clown:\n",
            "he sis, the stick ow the raisouses; hasten\n",
            "deave it to his tame for a dright his softrow:\n",
            "since your hand pitiederous than folly from.\n",
            "\n",
            "camillo:\n",
            "romeo, relige the sendy more the spirf'd.\n",
            "\n",
            "clown:\n",
            "thou drwind me disirneon'\n"
          ]
        }
      ]
    }
  ]
}